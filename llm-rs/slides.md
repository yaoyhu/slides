---
theme: seriph
background: ./image.png
# some information about your slides (markdown enabled)
title: LLMs in Remote Sensing
# apply unocss classes to the current slide
class: text-center
# https://sli.dev/features/drawing
drawings:
  persist: false
# slide transition: https://sli.dev/guide/animations.html#slide-transitions
transition: slide-left
# enable MDC Syntax: https://sli.dev/features/mdc
mdc: true
# open graph
seoMeta:
  # By default, Slidev will use ./og-image.png if it exists,
  # or generate one from the first slide if not found.
  ogImage: auto
  # ogImage: https://cover.sli.dev
fonts:
  sans: PingFang SC
  serif: PingFang SC
  mono: SF Mono
---

# LLMs in Remote Sensing
by [yaoyhu](https://github.com/yaoyhu)


<div class="abs-br m-6 text-xl">
  <a href="https://github.com/yaoyhu/slides/tree/main/llm-rs" target="_blank" class="slidev-icon-btn">
    <carbon:logo-github />
  </a>
</div>

<!--
The last comment block of each slide will be treated as slide notes. It will be visible and editable in Presenter Mode along with the slide. [Read more in the docs](https://sli.dev/guide/syntax.html#notes)
-->

---
transition: fade-out
layout: image-right
---

# Overview
1. ğŸ§‘â€ğŸ’» Implementation
   - Retrieval-Augmented Generation
   - Fine-tuning a Pre-trained Model
2. ğŸ’¬ Applications
   - Image Understanding
   - Cross-Modal Applications
3. ğŸ˜µ Unfinished tasks...
4. ğŸ“š TODOs

<!--
è¿™æ¬¡æˆ‘è¦æ±‡æŠ¥çš„å†…å®¹åˆ†ä¸‰ç‚¹ï¼š

1. æˆ‘åŠ¨æ‰‹å®ç°äº†ç®€å•çš„ RAG å’Œ å¾®è°ƒæµç¨‹ï¼Œä¸Šæ¬¡æˆ‘å…ˆæŠŠå¾®è°ƒæ’é™¤äº†ï¼Œè¿™æ¬¡æˆ‘åˆæŠŠå®ƒæ¬å›æ¥äº†ï¼Œåé¢ä¼šä»‹ç»åŸå› ã€‚

2. ç¬¬äºŒç‚¹æ›´åå‘äºè®¨è®ºï¼Œå°±æ˜¯åšä¸€ä¸ªä»€ä¹ˆæ ·çš„ LLMï¼Ÿ

3. æœ€åæ˜¯å’Œå¸ˆå§è¯·æ•™ä¸€ä¸‹ï¼Œä¸Šæ¬¡é‚£ç¯‡è®ºæ–‡æˆ‘çš„å¤ç°è¿›å±•å¾ˆæ…¢ã€‚
-->

---
transition: fade-out
layout: image-right
image: https://huggingface.co/ngxson/demo_simple_rag_py/resolve/main/diagram_4_mermaid--1446345905-light-mermaid.svg
backgroundSize: 30em 90%
---

# Retrieval-Augmented Generation

Tutorial: [Code a simple RAG from scratch](https://huggingface.co/blog/ngxson/make-your-own-rag)

1. **Dense Retrieval**: better embedding model + query rewriting
2. **Indexing**: [FAISS](https://github.com/facebookresearch/faiss) + compression strategies
3. **Ranking**: Precision@k evaluation + user feedback
4. **Prompt**: RAG-specific optimization + answer-aware retrieval

<!--
é¦–å…ˆæ˜¯ RAGï¼Œä»¥å‰ä¸€ç›´æŠŠå®ƒå½“ä½œä¸€ä¸ªå¾ˆç®€å•çš„å¤–éƒ¨æ•°æ®åº“ã€‚

å¾ˆä¹…ä¹‹å‰çš„ä¸€æ¬¡ç»„ä¼šæˆ‘ç”¨ LLaMAindex åº“æä¾›çš„ API å‡ åè¡Œä»£ç å°±å®ç°äº†ä¸€ä¸ªå¾ˆç®€å•çš„ RAGã€‚

æœ€è¿‘åœ¨çŸ¥ä¹çœ‹åˆ°ä¸€ä¸ªæé—®ï¼šRAG ä¼šä¸ä¼šæ¶ˆäº¡ï¼Ÿ
- æœ‰ä¸ªäººä»é¢è¯•çš„è§’åº¦ï¼šâ€œæˆ‘åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨LangChainæ­å»ºRAGçš„é“¾è·¯ï¼Œâ€
- çœ‹èµ·æ¥æ˜¯åšäº†ä¸€ç‚¹äº‹ï¼Œä½†ä¸»è¦å·¥ä½œéƒ½åœ¨åº“é‡Œè€Œä¸æ˜¯è‡ªå·±åšäº†ä»€ä¹ˆã€‚æ‰€ä»¥æˆ‘å°±æ‰¾äº†ä¸€äº›èµ„æºï¼Œå†™äº†ä¸€ä¸ªç®€åŒ–çš„å…¨æµç¨‹RAGï¼Œä½“ä¼šä¸€ä¸‹æ•´ä¸ª RAG çš„è¿‡ç¨‹ã€‚
-->

---

# Fine-Tuning a Pre-trained Model

1. Why Fine-Tuning?
   - [SpectralGPT](https://github.com/danfenghong/IEEE_TPAMI_SpectralGPT): The **pretraining** experiments were run on 8 NVIDIA RTX 4090 GPUs.
   - Finetune Dataset: EuroSAT & OSCD & SegMunich
   - ...
2. [Seven Stage Fine-Tuning Pipeline for LLM](https://arxiv.org/html/2408.13296v1#Ch2)
   - Data Preparation 
   - Model Initialization
   - Training Setup
   - Fine-tuning
   - Validation & Evaluation
   - Deployment
   - Monitoring

<!--
æˆ‘åœ¨è°ƒç ”çš„è¿‡ç¨‹ä¸­å‘ç°ï¼šå¾®è°ƒå¹¶æ²¡æœ‰é‚£ä¹ˆéº»çƒ¦ã€‚
-->

---
transition: slide-up
layout: image-right
image: https://github.com/ZhanYang-nwpu/Awesome-Remote-Sensing-Multimodal-Large-Language-Model/raw/main/images/1-timeline.jpg
backgroundSize: 30em 30%
---

# Current Applications

Reference: [Awesome-Remote-Sensing-Multimodal-Large-Language-Model](https://github.com/ZhanYang-nwpu/Awesome-Remote-Sensing-Multimodal-Large-Language-Model)

1. Image Understanding
   - Scene Description
   - Object/Change  Detection
2. Cross-Modal Applications
   - Text-to-Image Retrieval
   - Image-to-Text Generation
   - Visual Question Answering
3. ~~Chatbot~~: [GPT-5 not only matches but surpasses the performance of pre-licensed medical professionals in controlled QA/VQA evaluations, which raises both potential benefits and caution.](https://arxiv.org/pdf/2508.08224)

<!--
ç›®å‰LLMåœ¨é¥æ„Ÿæ–¹é¢çš„åº”
-->

---

# ğŸ¤¯ é¢„å¤„ç†ï¼šæ—¶é—´å¯¹é½

1. EMI çš„å®é™…è§‚æµ‹æ—¶é—´ï¼Ÿ
   - æ–‡ä»¶å `GF5B_EMI_20220601_003884_L10000140424_VI1.h5`
   - æ–‡ä»¶å±æ€§
   - å†…éƒ¨æ•°æ®
   - LV1 æ•°æ®è¯»å–
2. å›ºå®šè¿‡å¢ƒæ—¶é—´ + ç»åº¦è°ƒæ•´åçš„æ—¶åŒº
3. GAIA = MAE + DINO


---
layout: center
class: text-center
---

# TODOs

[LoRA](https://arxiv.org/abs/2106.09685) & [Q-LoRA](https://arxiv.org/abs/2305.14314)
